# my global config
global:
  scrape_interval:     10s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 10s # Evaluate rules every 15 seconds. The default is every 1 minute.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'codelab-monitor'

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
       #- localhost:8082
       - localhost:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - 't2_alert.yaml'

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:

  - job_name: 'spring-actuator'
    metrics_path: '/actuator/prometheus' #  defaults to '/metrics', scheme defaults to 'http'.
    scrape_interval: 10s
    static_configs:
      - targets: ['localhost:8087']

  - job_name: 'blackbox-exporter'
    scrape_interval: 10s
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
        # p.s. targets must be existing enpoints ;)
      - targets: ['provider-cs.default/actuator/prometheus']        
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: localhost:9115 # bb exporter at cluster


#  - job_name: 'spring-actuator'
#    metrics_path: '/actuator/prometheus' #  defaults to '/metrics', scheme defaults to 'http'.
#    scrape_interval: 5s
#    static_configs:
#      - targets: ['129.69.217.208:80']
#    #put endpoints of beckers cluster here. 129.69.217.208:80','
